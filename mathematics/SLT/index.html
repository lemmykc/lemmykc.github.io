<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content=""> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Singular Learning Theory (SLT) | Liam Carroll</title> <meta name="author" content="Liam K. Carroll"> <meta name="description" content="Mathematician, musician, hiker. I study Singular Learning Theory, conceive new concert mediums in Australian classical music, and guide on the Overland Track. "> <meta name="keywords" content="liam-carroll, singular-learning-theory, overland-track"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" type="image/png" href="/assets/img/lemmykc_github_favicon.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://lemmykc.github.io/mathematics/SLT/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <img src="/assets/img/lemmykc_github_favicon.png" width="26" height="26" alt="Custom Icon"> <a class="navbar-brand title font-weight-lighter" href="/"> Liam Carroll</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Mathematics</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/mathematics/SLT/">Singular Learning Theory</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/mathematics/notes/">Notes</a> </div> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Music</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/music/memorial-for-angus/">Memorial for Angus</a> </div> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Hiking</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/hiking/reflections/">Reflections</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/hiking/in%20wildness/">In Wildness</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/hiking/overland%20gallery/">Overland Gallery</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Singular Learning Theory (SLT)</h1> <p class="post-description"></p> </header> <article> <p>At present my research is focused on the application of Singular Learning Theory to the understanding of deep learning (AI) models like neural networks and transformers. With a newfound interest in AI Safety and Alignment, I am currently working on the <a href="https://www.lesswrong.com/s/SfFQE8DXbgkjk62JK/p/TjaeCWvLZtEDAS5Ex" rel="external nofollow noopener" target="_blank">Developmental Interpretability</a> agenda.</p> <h1 id="writing">Writing</h1> <h2 id="phase-transitions-in-neural-networks---masters-thesis"> <a href="PhaseTransitions_NeuralNetworks_LiamCarroll.pdf">Phase Transitions in Neural Networks</a> - Master’s Thesis</h2> <p><strong>Supervisor:</strong> <a href="http://therisingsea.org" rel="external nofollow noopener" target="_blank">Dr. Daniel Murfet</a>. <br> <strong>Date:</strong> October 2021 <br> <strong>Summary:</strong> The thesis studies Sumio Watanabe’s <em>Singular Learning Theory</em> (SLT) and explores how it can be used to explain why neural networks generalise so well, and how to think about and analyse phase transitions in deep learning. I illustrate some important aspects of Watanabe’s theory for small neural networks by examining the relationship between singularities, phases and phase transitions. I demonstrate the existence of both first and second order phase transitions in the Bayesian posterior for simple ReLU neural networks by varying the true distribution.</p> <p>You can find the code used to generate my Bayesian posterior experiments using HMC <a href="https://github.com/lemmykc/phase-transitions-neural-networks" rel="external nofollow noopener" target="_blank">here</a>.</p> <p>If you would like to cite this work please use the following BibTeX reference:</p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@mastersthesis</span><span class="p">{</span><span class="nl">carroll2021phase</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Phase Transitions in Neural Networks}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Liam Carroll}</span><span class="p">,</span>
  <span class="na">month</span><span class="p">=</span><span class="s">{October}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2021}</span><span class="p">,</span>
  <span class="na">school</span><span class="p">=</span><span class="s">{The University of Melbourne}</span><span class="p">,</span>
  <span class="na">url</span><span class="p">=</span><span class="s">{http://therisingsea.org/notes/MSc-Carroll.pdf}</span><span class="p">,</span>
  <span class="na">type</span><span class="p">=</span><span class="s">{Master's Thesis}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="distilling-singular-learning-theory-on-lesswrong"> <a href="https://www.lesswrong.com/s/czrXjvCLsqGepybHC" rel="external nofollow noopener" target="_blank">Distilling Singular Learning Theory</a> on LessWrong</h2> <p>Thanks to a grant from the <a href="https://funds.effectivealtruism.org/funds/far-future" rel="external nofollow noopener" target="_blank">Long Term Future Fund</a>, I have written a LessWrong sequence called Distilling SLT which translates the key lessons, claims and findings of my masters thesis into a more palatable format. The posts were published to coincide with the initial Workshop on <a href="https://devinterp.com" rel="external nofollow noopener" target="_blank">Singular Learning Theory and Alignment</a>.</p> <p>If you would like to cite this work please use the following BibTeX reference:</p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">DSLT2023lesswrong</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Distilling Singular Learning Theory}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Liam Carroll}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2023}</span><span class="p">,</span>
  <span class="na">howpublished</span><span class="p">=</span><span class="s">{\url{https://www.lesswrong.com/s/czrXjvCLsqGepybHC}}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="growth-and-form-in-a-toy-model-of-superposition-on-lesswrong"> <a href="https://www.lesswrong.com/posts/jvGqQGDrYzZM4MyaN/growth-and-form-in-a-toy-model-of-superposition" rel="external nofollow noopener" target="_blank">Growth and Form in a Toy Model of Superposition</a> on LessWrong</h2> <p>This post distills <a href="https://arxiv.org/abs/2310.06301" rel="external nofollow noopener" target="_blank">Dynamical and Bayesian Phase Transitions in a Toy Model of Superposition</a> by Chen et al. (2023), where they study developmental stages of the Toy Model of Superposition, understanding growth and form from the perspective of SLT. This work was supported by Lightspeed grants.</p> <p>If you would like to cite this work please use the following BibTeX reference:</p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">TMS1_2023lesswrong</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Growth and Form in a Toy Model of Superposition}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Liam Carroll AND Edmund Lau}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2023}</span><span class="p">,</span>
  <span class="na">howpublished</span><span class="p">=</span><span class="s">{\url{https://www.lesswrong.com/posts/jvGqQGDrYzZM4MyaN/growth-and-form-in-a-toy-model-of-superposition}}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div> <h1 id="talks">Talks</h1> <h2 id="talk-at-slt-summit-for-alignment-june-2023">Talk at SLT Summit for Alignment June 2023</h2> <p>In this talk I present the key ideas of the Singular Learning Theory perspective on phase transitions in statistical models. I show toy examples of simple loss landscapes that demonstrate why the RLCT is so important to phase transitions, and present the work from my masters thesis which demonstrates examples of first and second order phase transitions in two layer feedforward ReLU neural networks.</p> <div style="text-align:center; margin-top:20px; margin-bottom:20px;"> <iframe width="364" height="205" src="https://www.youtube.com/embed/yxv8aDPHI9A" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> </div> <h2 id="masters-completion-talk">Master’s Completion Talk</h2> <p>In this talk I explain how to inerpret the phase transitions demonstrated in my thesis through the lens of Singular Learning Theory to an audience of fellow Master’s students.</p> <div style="text-align:center; margin-top:20px; margin-bottom:20px;"> <iframe width="364" height="205" src="https://www.youtube.com/embed/S-SxM2-7tiY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> </div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>